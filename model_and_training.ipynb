{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ThpHLlGK44y4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ZW1-Djhc5GTQ",
    "outputId": "4c4bc44b-f1a8-4f8c-9f7a-c8c52990e411"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>response_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they do to</td>\n",
       "      <td>they do not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she okay</td>\n",
       "      <td>i hope so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow</td>\n",
       "      <td>let us go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>okay youre gonna need to learn how to lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what crap</td>\n",
       "      <td>me this endless blonde babble i am like boring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>do you listen to this crap</td>\n",
       "      <td>what crap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>but</td>\n",
       "      <td>you always been this selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>then that is all you had to say</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>well no</td>\n",
       "      <td>then that is all you had to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i wa</td>\n",
       "      <td>you never wanted to go out with me did you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         input_text  \\\n",
       "0                        they do to   \n",
       "1                          she okay   \n",
       "2                               wow   \n",
       "3                                no   \n",
       "6                         what crap   \n",
       "7        do you listen to this crap   \n",
       "8                               but   \n",
       "9   then that is all you had to say   \n",
       "10                          well no   \n",
       "11                             i wa   \n",
       "\n",
       "                                      response_output  \n",
       "0                                         they do not  \n",
       "1                                           i hope so  \n",
       "2                                           let us go  \n",
       "3           okay youre gonna need to learn how to lie  \n",
       "6   me this endless blonde babble i am like boring...  \n",
       "7                                           what crap  \n",
       "8                        you always been this selfish  \n",
       "9                                                 but  \n",
       "10                    then that is all you had to say  \n",
       "11         you never wanted to go out with me did you  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in clean data\n",
    "data = pd.read_pickle('data/input_data.pkl')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "GuOUUk9D5J0P",
    "outputId": "ca15bd56-a6f0-4f0d-e2b9-d20b9b98f9be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>response_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they do to</td>\n",
       "      <td>&lt;start&gt; they do not &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she okay</td>\n",
       "      <td>&lt;start&gt; i hope so &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow</td>\n",
       "      <td>&lt;start&gt; let us go &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_text            response_output\n",
       "0  they do to  <start> they do not <end>\n",
       "1    she okay    <start> i hope so <end>\n",
       "2         wow    <start> let us go <end>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Append start and end to each response_output\n",
    "data['response_output'] = '<start> ' + data['response_output'].astype(str) + ' <end>'\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1-5_X1h5Mxn",
    "outputId": "d5372ee8-b6ac-4fc8-cf06-ba797bfdb405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocab size: 25828, target vocab size: 43782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize tokenizers\n",
    "tokenizer_input = Tokenizer(filters='', oov_token='<unk>')\n",
    "tokenizer_target = Tokenizer(filters='', oov_token='<unk>')\n",
    "\n",
    "tokenizer_input.fit_on_texts(data['input_text'].values)\n",
    "tokenizer_target.fit_on_texts(data['response_output'].values)\n",
    "\n",
    "input_vocab = tokenizer_input.word_index.keys()\n",
    "target_vocab = tokenizer_target.word_index.keys()\n",
    "print(f'input vocab size: {len(input_vocab)}, target vocab size: {len(target_vocab)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3scfp6T5R96",
    "outputId": "895dc55b-299d-4fe8-bd46-eca17242d1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: (450680, 40)\n",
      "Decoder input shape: (450680, 40)\n",
      "Decoder target shape: (450680, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = 40\n",
    "\n",
    "# Tokenize and pad data\n",
    "input_seqs = tokenizer_input.texts_to_sequences(data['input_text'])\n",
    "input_seqs_padded = pad_sequences(input_seqs, maxlen=max_length, padding='post')\n",
    "encoder_input = np.array(input_seqs_padded)\n",
    "print(f'Encoder input shape: {encoder_input.shape}')\n",
    "\n",
    "target_seqs = tokenizer_target.texts_to_sequences(data['response_output'])\n",
    "target_seqs_padded = pad_sequences(target_seqs, maxlen=max_length, padding='post')\n",
    "decoder_input = np.array(target_seqs_padded)\n",
    "print(f'Decoder input shape: {target_seqs_padded.shape}')\n",
    "\n",
    "# Create decoder target data\n",
    "decoder_target_lines = []\n",
    "for line in target_seqs:\n",
    "    # Take every token after the <start> token\n",
    "    decoder_target_lines.append(line[1:])\n",
    "    \n",
    "decoder_target_seqs = pad_sequences(decoder_target_lines, maxlen=max_length, padding='post')\n",
    "decoder_target = np.array(decoder_target_seqs)\n",
    "print(f'Decoder target shape: {decoder_target.shape}')\n",
    "\n",
    "# Save tokenizers to pickle file\n",
    "with open('tokenizer_input.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer_input, file)\n",
    "\n",
    "with open('tokenizer_target.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer_target, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GtkekvLO5Vlo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train and validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "encoder_input_train, encoder_input_val, decoder_input_train, decoder_input_val, decoder_target_train, decoder_target_val = train_test_split(\n",
    "    encoder_input, decoder_input, decoder_target, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iPtxyu0S-7eX"
   },
   "outputs": [],
   "source": [
    "\n",
    "glove_files = ['glove.6B.50d.txt', 'glove.6B.100d.txt', 'glove.6B.200d.txt', 'glove.6B.300d.txt']\n",
    "\n",
    "# Load in GloVe pre trained word embeddings\n",
    "glove_model = {}\n",
    "\n",
    "for file_path in glove_files:\n",
    "    with open(f'{file_path}', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_model[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "owpuhjRt-8JV"
   },
   "outputs": [],
   "source": [
    "\n",
    "vector_dim = len(next(iter(glove_model.values())))\n",
    "\n",
    "# Initialize encoder embedding matrix\n",
    "enc_embedding_matrix = np.zeros((len(tokenizer_input.word_index) + 1, vector_dim))\n",
    "\n",
    "for word, i in tokenizer_input.word_index.items():\n",
    "    if word in glove_model:\n",
    "        enc_embedding_matrix[i] = glove_model[word]\n",
    "\n",
    "# Initialize decoder embedding matrix\n",
    "dec_embedding_matrix = np.zeros((len(tokenizer_target.word_index) + 1, vector_dim))\n",
    "\n",
    "for word, i in tokenizer_target.word_index.items():\n",
    "    if word in glove_model:\n",
    "        dec_embedding_matrix[i] = glove_model[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfciXSZZomKv"
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22149hQx5gRH",
    "outputId": "d848dc82-bee7-4cb5-96d4-65b34d4ace63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 300)            3372600   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 300)            3799500   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 200),                400800    ['embedding[0][0]']           \n",
      "                              (None, 200),                                                        \n",
      "                              (None, 200)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 200),          400800    ['embedding_1[0][0]',         \n",
      "                              (None, 200),                           'lstm[0][1]',                \n",
      "                              (None, 200)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 12665)          2545665   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10519365 (40.13 MB)\n",
      "Trainable params: 3347265 (12.77 MB)\n",
      "Non-trainable params: 7172100 (27.36 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_vocab_size = len(input_vocab) + 1\n",
    "target_vocab_size = len(target_vocab) + 1\n",
    "\n",
    "# Model encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None , ))\n",
    "# Use GloVe embeddings\n",
    "enc_embedding_layer =  tf.keras.layers.Embedding(\n",
    "    input_dim=input_vocab_size,\n",
    "    output_dim=300,\n",
    "    weights=[enc_embedding_matrix],\n",
    "    input_length=max_length,\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")\n",
    "encoder_embedding = enc_embedding_layer(encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM(200, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h , state_c]\n",
    "\n",
    "# Model decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None ,  ))\n",
    "dec_embedding_layer =  tf.keras.layers.Embedding(\n",
    "    input_dim=target_vocab_size,\n",
    "    output_dim=300,\n",
    "    weights=[dec_embedding_matrix],\n",
    "    input_length=max_length,\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")\n",
    "decoder_embedding = dec_embedding_layer(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(200, return_state=True, return_sequences=True)\n",
    "decoder_outputs , _ , _ = decoder_lstm (decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(target_vocab_size, activation=tf.keras.activations.softmax)\n",
    "output = decoder_dense (decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaoE2lwa5jti",
    "outputId": "1e3d341b-fa4a-490b-a6c3-bfbef98f4337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3912/3912 [==============================] - 64s 14ms/step - loss: 4.9094 - val_loss: 4.6082\n",
      "Epoch 2/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.5167 - val_loss: 4.4517\n",
      "Epoch 3/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.3966 - val_loss: 4.3661\n",
      "Epoch 4/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 4.3151 - val_loss: 4.2993\n",
      "Epoch 5/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.2458 - val_loss: 4.2372\n",
      "Epoch 6/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 4.1829 - val_loss: 4.1801\n",
      "Epoch 7/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.1209 - val_loss: 4.1260\n",
      "Epoch 8/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.0617 - val_loss: 4.0657\n",
      "Epoch 9/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 4.0043 - val_loss: 4.0190\n",
      "Epoch 10/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.9474 - val_loss: 3.9711\n",
      "Epoch 11/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.8911 - val_loss: 3.9174\n",
      "Epoch 12/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.8352 - val_loss: 3.8712\n",
      "Epoch 13/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.7797 - val_loss: 3.8229\n",
      "Epoch 14/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.7260 - val_loss: 3.7739\n",
      "Epoch 15/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.6746 - val_loss: 3.7383\n",
      "Epoch 16/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.6275 - val_loss: 3.6903\n",
      "Epoch 17/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.5817 - val_loss: 3.6539\n",
      "Epoch 18/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.5393 - val_loss: 3.6244\n",
      "Epoch 19/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.4992 - val_loss: 3.5842\n",
      "Epoch 20/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.4632 - val_loss: 3.5527\n",
      "Epoch 21/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.4271 - val_loss: 3.5198\n",
      "Epoch 22/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.3952 - val_loss: 3.4982\n",
      "Epoch 23/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.3667 - val_loss: 3.4731\n",
      "Epoch 24/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.3394 - val_loss: 3.4604\n",
      "Epoch 25/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.3144 - val_loss: 3.4390\n",
      "Epoch 26/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.2920 - val_loss: 3.4225\n",
      "Epoch 27/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.2717 - val_loss: 3.4061\n",
      "Epoch 28/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.2513 - val_loss: 3.3935\n",
      "Epoch 29/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.2340 - val_loss: 3.3782\n",
      "Epoch 30/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.2171 - val_loss: 3.3739\n",
      "Epoch 31/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.1996 - val_loss: 3.3569\n",
      "Epoch 32/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1844 - val_loss: 3.3542\n",
      "Epoch 33/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1720 - val_loss: 3.3654\n",
      "Epoch 34/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1574 - val_loss: 3.3317\n",
      "Epoch 35/50\n",
      "3912/3912 [==============================] - 54s 14ms/step - loss: 3.1458 - val_loss: 3.3339\n",
      "Epoch 36/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1310 - val_loss: 3.3423\n",
      "Epoch 37/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1198 - val_loss: 3.3119\n",
      "Epoch 38/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.1090 - val_loss: 3.3114\n",
      "Epoch 39/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0967 - val_loss: 3.3199\n",
      "Epoch 40/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0870 - val_loss: 3.3135\n",
      "Epoch 41/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0779 - val_loss: 3.3056\n",
      "Epoch 42/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0679 - val_loss: 3.3153\n",
      "Epoch 43/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0596 - val_loss: 3.3120\n",
      "Epoch 44/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0486 - val_loss: 3.3028\n",
      "Epoch 45/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0376 - val_loss: 3.2837\n",
      "Epoch 46/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0273 - val_loss: 3.2857\n",
      "Epoch 47/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0157 - val_loss: 3.2864\n",
      "Epoch 48/50\n",
      "3912/3912 [==============================] - 53s 14ms/step - loss: 3.0083 - val_loss: 3.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [encoder_input_train, decoder_input_train], decoder_target_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_target_val),\n",
    "    batch_size=50, epochs=50, callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save model, model weights, and model history\n",
    "model.save('model.h5')\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "with open('model_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "v6nkQSnr5wXY",
    "outputId": "deb9a220-c646-4a9c-f0ee-7761efbd25b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9_3X1qel5xVr"
   },
   "outputs": [],
   "source": [
    "\n",
    "''' Define inference model to use encoder and decoder from the model'''\n",
    "def make_inference_models():\n",
    "\n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(200, ))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(200, ))\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs\n",
    "    )\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states\n",
    "    )\n",
    "\n",
    "    return encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUodtUTl5y8J",
    "outputId": "86701e98-e4d0-4cef-d959-5e978427927f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something: hi\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " hi <end>\n",
      "Say something: hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      " hello <end>\n",
      "Say something: what is up\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " nothing much what is going on <end>\n",
      "Say something: what up dude\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " well i am going to be back <end>\n",
      "Say something: i love you\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " i love you too <end>\n",
      "Say something: aww thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " i am not sure i am not sure <end>\n",
      "Say something: thank you\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " i am so happy for you <end>\n",
      "Say something: happy for me?\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      " i am not sure i am not sure <end>\n",
      "Say something: not sure about what\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " i am not sure <end>\n",
      "Say something: well bye now\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      " i am not not sure i am not sure <end>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' Turn a string into padded, tokenized data that the encoder can use'''\n",
    "def str_to_tokens(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        if word in tokenizer_input.word_index:\n",
    "            tokens_list.append(tokenizer_input.word_index[word])\n",
    "        else:\n",
    "            tokens_list.append(tokenizer_input.word_index['<unk>'])\n",
    "    return pad_sequences([tokens_list], maxlen=max_length , padding='post')\n",
    "\n",
    "\n",
    "# Initialize encoder and decoder inference models\n",
    "enc_model, dec_model = make_inference_models()\n",
    "\n",
    "\n",
    "''' This loop gets input from the user and gets a response from chatbot'''\n",
    "for _ in range(10):\n",
    "    \n",
    "    # Predict state values from input\n",
    "    states_values = enc_model.predict(str_to_tokens(input('Say something: ' )))\n",
    "    \n",
    "    # Initialize target sequence as empty and give it start token\n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = tokenizer_target.word_index['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Decode the model's response\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
    "        \n",
    "        # Get index of the next predicted word\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "        sampled_word = None\n",
    "\n",
    "        # Find where the indices match up and get predicted word\n",
    "        for word, index in tokenizer_target.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_sentence += ' {}'.format(word)\n",
    "                sampled_word = word\n",
    "        \n",
    "        # If model predict end token or if over 40 tokens long end model response\n",
    "        if sampled_word == '<end>' or len(decoded_sentence.split()) > max_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Reset target sequence\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "        \n",
    "        # Update state values \n",
    "        states_values = [h, c]\n",
    "\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This model definitely shows some promise, as it can correctly respond to some basic phrases, like \"I love you\" and \"what is up.\" Even when it responds incorrectly, the sentences are still comprehensive, which is good. \n",
    "\n",
    "This model's performance can only be increased in a few ways. Increasing the training data size and making the model's architecture more complex are the best methods of doing so. Unfortunately, adding to the model's architecture with only one more LSTM layer in the encoder and decoder causes the training time to increase almost tenfold. Also, increasing the training data size has  diminishing returns on the increase of the model's performance, requiring me to significantly increase the amount of data to see any significant improvement. To do either of these, I would need a powerful GPU...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeIfwJWyRwg5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
